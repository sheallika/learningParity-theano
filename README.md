------------------------------------------------------------
Exeprimentation with different architectures (Shallow MLP, Deep MLP, RNN, LSTM) for Parity function Learning, and anlayzing the minimum number of neurons required for each case.

Observed that: The LSTM has 1 hidden layer and using only 1 hidden unit 100% test accuracy can be achieved for parity function for both 8 bit and 12 bit sequences. The hidden units required in LSTM to learn parity function are the least.
 

